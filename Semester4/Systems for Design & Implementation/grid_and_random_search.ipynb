{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "1bIAHHfccT9p",
        "outputId": "c395667f-6a4a-4a5b-ba41-01e662f4436e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-f41e09ed12fd>:14: DtypeWarning: Columns (15,17,24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of entries (rows): 479857\n",
            "Number of entries (rows) after sampling 10%: 143957\n",
            "Fitting 5 folds for each of 972 candidates, totalling 4860 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-f41e09ed12fd>\u001b[0m in \u001b[0;36m<cell line: 57>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# Fit Grid Search with a progress bar using dask ProgressBar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mProgressBar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;31m# Get the best parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1761\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from dask.diagnostics import ProgressBar\n",
        "\n",
        "# Load the dataset\n",
        "file_path =\"/content/drive/MyDrive/1_ord_lax_sorted_wDaysBeforeDeparture_bestTimePurchase_day_month_wDayOfWeek_wHolidays_wDurationMinutes_wCount_time_filterd_14_layovers.csv\"\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "print(\"Number of entries (rows):\", df.shape[0])\n",
        "\n",
        "columns_to_keep = [\n",
        "    'daysBeforeFlight',\n",
        "    'flightDay', 'flightMonth',\n",
        "    'flightDayOfWeek', 'nearHoliday', 'bestTimeToPurchase',\n",
        "    'departureHour', 'departureMinute', 'arrivalMinute', 'arrivalHour', 'travelDurationMinutes'\n",
        "]\n",
        "\n",
        "df_filtered = df[columns_to_keep]\n",
        "\n",
        "# Sample 10% of the dataset\n",
        "df_sampled = df_filtered.sample(frac=0.3, random_state = 42)\n",
        "print(\"Number of entries (rows) after sampling 10%:\", df_sampled.shape[0])\n",
        "\n",
        "# Define features and target variable\n",
        "X = df_sampled.drop('bestTimeToPurchase', axis=1)\n",
        "y = df_sampled['bestTimeToPurchase']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the parameter grid\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_features': [2, 3, 4],\n",
        "    'max_depth': [20, 30, 40],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False],\n",
        "    'max_samples': [0.5, 0.7]\n",
        "}\n",
        "\n",
        "# Initialize the model\n",
        "rf_regressor = RandomForestRegressor()\n",
        "\n",
        "# Initialize Grid Search\n",
        "grid_search = GridSearchCV(estimator=rf_regressor, param_grid=param_dist, cv=5, scoring='neg_mean_squared_error',\n",
        "                           n_jobs=-1, verbose=1)\n",
        "\n",
        "# Fit Grid Search with a progress bar using dask ProgressBar\n",
        "with ProgressBar():\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = grid_search.best_params_\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "\n",
        "# Train the model with the best parameters\n",
        "best_rf_regressor = grid_search.best_estimator_\n",
        "best_rf_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = best_rf_regressor.predict(X_test)\n",
        "\n",
        "# Calculate and print RMSE for the test data\n",
        "rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(f\"RMSE on Test Data: {rmse}\")\n",
        "\n",
        "# Perform cross-validation with 10 folds on the best model\n",
        "cv_scores = cross_val_score(best_rf_regressor, X, y, cv=10, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Convert negative mean squared error to positive\n",
        "cv_scores = -cv_scores\n",
        "\n",
        "# Calculate RMSE for each fold\n",
        "rmse_scores = [sqrt(score) for score in cv_scores]\n",
        "\n",
        "print(f\"Cross-Validation RMSE Scores: {rmse_scores}\")\n",
        "print(f\"Mean RMSE: {sum(rmse_scores) / len(rmse_scores)}\")\n",
        "print(f\"Standard Deviation of RMSE: {pd.Series(rmse_scores).std()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from dask.diagnostics import ProgressBar\n",
        "\n",
        "# Load the dataset\n",
        "file_path =\"/content/drive/MyDrive/1_ord_lax_sorted_wDaysBeforeDeparture_bestTimePurchase_day_month_wDayOfWeek_wHolidays_wDurationMinutes_wCount_time_filterd_14_layovers.csv\"\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "print(\"Number of entries (rows):\", df.shape[0])\n",
        "\n",
        "columns_to_keep = [\n",
        "    'daysBeforeFlight',\n",
        "    'flightDay', 'flightMonth',\n",
        "    'flightDayOfWeek', 'nearHoliday', 'bestTimeToPurchase',\n",
        "    'departureHour', 'departureMinute', 'arrivalMinute', 'arrivalHour', 'travelDurationMinutes'\n",
        "]\n",
        "\n",
        "df_filtered = df[columns_to_keep]\n",
        "\n",
        "# Sample 30% of the dataset\n",
        "df_sampled = df_filtered.sample(frac=0.3, random_state=42)\n",
        "print(\"Number of entries (rows) after sampling 30%:\", df_sampled.shape[0])\n",
        "\n",
        "# Define features and target variable\n",
        "X = df_sampled.drop('bestTimeToPurchase', axis=1)\n",
        "y = df_sampled['bestTimeToPurchase']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the parameter grid\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_features': [2, 3, 4],\n",
        "    'max_depth': [20, 30, 40],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False],\n",
        "    'max_samples': [0.5, 0.7]\n",
        "}\n",
        "\n",
        "# Initialize the model\n",
        "rf_regressor = RandomForestRegressor()\n",
        "\n",
        "# Initialize Randomized Search\n",
        "random_search = RandomizedSearchCV(estimator=rf_regressor, param_distributions=param_dist, cv=5, scoring='neg_mean_squared_error',\n",
        "                                   n_jobs=-1, verbose=1, n_iter=100, random_state=42)\n",
        "\n",
        "# Fit Randomized Search with a progress bar using dask ProgressBar\n",
        "with ProgressBar():\n",
        "    random_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = random_search.best_params_\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "\n",
        "# Train the model with the best parameters\n",
        "best_rf_regressor = random_search.best_estimator_\n",
        "best_rf_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = best_rf_regressor.predict(X_test)\n",
        "\n",
        "# Calculate and print RMSE for the test data\n",
        "rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(f\"RMSE on Test Data: {rmse}\")\n",
        "\n",
        "# Perform cross-validation with 10 folds on the best model\n",
        "cv_scores = cross_val_score(best_rf_regressor, X, y, cv=10, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Convert negative mean squared error to positive\n",
        "cv_scores = -cv_scores\n",
        "\n",
        "# Calculate RMSE for each fold\n",
        "rmse_scores = [sqrt(score) for score in cv_scores]\n",
        "\n",
        "print(f\"Cross-Validation RMSE Scores: {rmse_scores}\")\n",
        "print(f\"Mean RMSE: {sum(rmse_scores) / len(rmse_scores)}\")\n",
        "print(f\"Standard Deviation of RMSE: {pd.Series(rmse_scores).std()}\")\n"
      ],
      "metadata": {
        "id": "DY9UZ2Z3Yiy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Parameters: {'bootstrap': True, 'max_depth': 40, 'max_features': 2, 'max_samples': 0.7, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
        "RMSE on Test Data: 4.378777304035373\n",
        "Cross-Validation RMSE Scores: [4.1457766546778, 4.179370658340349, 4.167067577173025, 4.174058025015905, 4.080473281385968, 4.1492263693656435, 4.085152835497481, 4.072493006920212, 4.292280010709814, 3.923740294907137]\n",
        "Mean RMSE: 4.126963871399334\n",
        "Standard Deviation of RMSE: 0.0959907623960586\n",
        "\n",
        "Process finished with exit code 0"
      ],
      "metadata": {
        "id": "bi0vV_zZcpFP"
      }
    }
  ]
}